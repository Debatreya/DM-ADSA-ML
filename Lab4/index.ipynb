{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Experiment 4 : Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply different missing values handing methods  namely  \n",
    "- Ignore  the  tuple,\n",
    "- Use  a  global  constant  to  fill  in  the missing value, \n",
    "- Use a measure of central tendency for the attribute (e.g., the mean or median) to fill in the missing value, \n",
    "- Use the attribute mean or median for all samples belonging to the same class as the given tuple, \n",
    "- Use the  most  probable  value  to  fill  in  the  missing  value  on  your  datasets. \n",
    "- Further, address  the  issue  of  noisy  data  points  still  pertaining  in  the datasets even after handling the missing values using \n",
    "    - Binning and \n",
    "    - Regression methods. \n",
    "- Analyze the effect of different techniques on dataset in terms of statistical parameters such as central tendency and dispersion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0      52    1   0       125   212    0        1      168      0      1.0   \n",
       "1      53    1   0       140   203    1        0      155      1      3.1   \n",
       "2      70    1   0       145   174    0        1      125      1      2.6   \n",
       "3      61    1   0       148   203    0        1      161      0      0.0   \n",
       "4      62    0   0       138   294    1        1      106      0      1.9   \n",
       "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
       "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
       "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
       "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
       "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
       "\n",
       "      slope  ca  thal  target  \n",
       "0         2   2     3       0  \n",
       "1         0   0     3       0  \n",
       "2         0   0     3       0  \n",
       "3         2   1     3       0  \n",
       "4         1   3     2       0  \n",
       "...     ...  ..   ...     ...  \n",
       "1020      2   0     2       1  \n",
       "1021      1   1     3       0  \n",
       "1022      1   1     2       0  \n",
       "1023      2   0     2       1  \n",
       "1024      1   1     3       0  \n",
       "\n",
       "[1025 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "# column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "# heart_df = pd.read_csv(url, header=None, names=column_names, na_values='?')\n",
    "\n",
    "url = \"../heart/heart.csv\"\n",
    "heart_df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows and summary statistics\n",
    "heart_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows having null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after ignoring tuples with missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Ignore the tuples with missing values\n",
    "heart_df_ignored = heart_df.dropna()\n",
    "print(\"Dataset after ignoring tuples with missing values:\")\n",
    "print(heart_df_ignored.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Missing with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after using global constant to fill missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "heart_df_global_constant = heart_df.fillna(-1)\n",
    "\n",
    "print(\"Dataset after using global constant to fill missing values:\")\n",
    "print(heart_df_global_constant.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a Measure of Central Tendency (Mean/Median) to fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after using mean to fill missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n",
      "Dataset after using median to fill missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with the mean\n",
    "heart_df_mean = heart_df.fillna(heart_df.mean())\n",
    "\n",
    "# Fill missing values with the median\n",
    "heart_df_median = heart_df.fillna(heart_df.median())\n",
    "\n",
    "print(\"Dataset after using mean to fill missing values:\")\n",
    "print(heart_df_mean.info())\n",
    "\n",
    "print(\"Dataset after using median to fill missing values:\")\n",
    "print(heart_df_median.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values using the mean or median for samples belonging to the same class (e.g., the same target class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after using class mean to fill missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n",
      "Dataset after using class median to fill missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debat\\AppData\\Local\\Temp\\ipykernel_15200\\535031063.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  heart_df_class_mean[column].fillna(heart_df.groupby('target')[column].transform('mean'), inplace=True)\n",
      "C:\\Users\\debat\\AppData\\Local\\Temp\\ipykernel_15200\\535031063.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  heart_df_class_median[column].fillna(heart_df.groupby('target')[column].transform('median'), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values using the mean of the same class\n",
    "heart_df_class_mean = heart_df.copy()\n",
    "for column in heart_df.columns:\n",
    "    heart_df_class_mean[column].fillna(heart_df.groupby('target')[column].transform('mean'), inplace=True)\n",
    "\n",
    "# Fill missing values using the median of the same class\n",
    "heart_df_class_median = heart_df.copy()\n",
    "for column in heart_df.columns:\n",
    "    heart_df_class_median[column].fillna(heart_df.groupby('target')[column].transform('median'), inplace=True)\n",
    "\n",
    "print(\"Dataset after using class mean to fill missing values:\")\n",
    "print(heart_df_class_mean.info())\n",
    "\n",
    "print(\"Dataset after using class median to fill missing values:\")\n",
    "print(heart_df_class_median.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values with the most probable value, which could be inferred through methods like regression, k-NN, or similar techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after using mode to fill missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with the most probable value (mode)\n",
    "heart_df_mode = heart_df.apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "print(\"Dataset after using mode to fill missing values:\")\n",
    "print(heart_df_mode.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Noisy Data Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning Method\n",
    "Binning is a simple technique that smooths noisy data by grouping it into bins and then replacing the values within each bin with a representative value (such as the mean, median, or boundaries).\n",
    "\n",
    "Steps for Binning:\n",
    "\n",
    "- Equal-width Binning: Divides the range of the data into equal-sized intervals.\n",
    "- Equal-frequency Binning: Divides the data into intervals that each contain approximately the same number of data points.\n",
    "\n",
    "We'll apply equal-width binning to smooth the chol (cholesterol) attribute, which might have noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after applying equal-width binning on 'chol' attribute:\n",
      "        chol  chol_binned\n",
      "0  204.80083            0\n",
      "1  204.80083            0\n",
      "2  204.80083            0\n",
      "3  204.80083            0\n",
      "4  276.40619            1\n"
     ]
    }
   ],
   "source": [
    "# Apply equal-width binning on 'chol' attribute\n",
    "heart_df_binned = heart_df_mean.copy()\n",
    "\n",
    "# Define the number of bins\n",
    "num_bins = 4\n",
    "\n",
    "# Binning using pandas cut function\n",
    "heart_df_binned['chol_binned'] = pd.cut(heart_df_binned['chol'], bins=num_bins, labels=False)\n",
    "\n",
    "# Replace original 'chol' values with bin means\n",
    "bin_means = heart_df_binned.groupby('chol_binned')['chol'].mean()\n",
    "heart_df_binned['chol'] = heart_df_binned['chol_binned'].map(bin_means)\n",
    "\n",
    "print(\"Dataset after applying equal-width binning on 'chol' attribute:\")\n",
    "print(heart_df_binned[['chol', 'chol_binned']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Method\n",
    "Regression can be used to predict and smooth out noisy data by fitting a regression model to the data. We'll use linear regression to predict the trestbps (resting blood pressure) attribute based on other attributes and replace its values with the predicted ones to smooth the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after applying regression on 'trestbps' attribute:\n",
      "     trestbps\n",
      "0  127.606252\n",
      "1  143.082032\n",
      "2  137.413752\n",
      "3  128.398309\n",
      "4  138.927470\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Prepare data for regression\n",
    "regression_df = heart_df_mean.dropna(subset=['trestbps'])\n",
    "X = regression_df.drop(['trestbps', 'target'], axis=1)\n",
    "y = regression_df['trestbps']\n",
    "\n",
    "# Fit a linear regression model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, y)\n",
    "\n",
    "# Predict 'trestbps' values\n",
    "heart_df_regression = heart_df_mean.copy()\n",
    "predicted_trestbps = regressor.predict(heart_df_regression.drop(['trestbps', 'target'], axis=1))\n",
    "heart_df_regression['trestbps'] = predicted_trestbps\n",
    "\n",
    "print(\"Dataset after applying regression on 'trestbps' attribute:\")\n",
    "print(heart_df_regression[['trestbps']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Effect of Different Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Ignoring Tuples:\n",
      "Statistics for chol:\n",
      "Mean: 246.0, Median: 240.0, Mode: 204\n",
      "Range: 438, Variance: 2661.787109375, Standard Deviation: 51.59251020618206\n",
      "\n",
      "Statistics for trestbps:\n",
      "Mean: 131.61170731707318, Median: 130.0, Mode: 120\n",
      "Range: 106, Variance: 306.835409679878, Standard Deviation: 17.516718005376408\n",
      "\n",
      "After Filling with Global Constant:\n",
      "Statistics for chol:\n",
      "Mean: 246.0, Median: 240.0, Mode: 204\n",
      "Range: 438, Variance: 2661.787109375, Standard Deviation: 51.59251020618206\n",
      "\n",
      "Statistics for trestbps:\n",
      "Mean: 131.61170731707318, Median: 130.0, Mode: 120\n",
      "Range: 106, Variance: 306.835409679878, Standard Deviation: 17.516718005376408\n",
      "\n",
      "After Filling with Mean:\n",
      "Statistics for chol:\n",
      "Mean: 246.0, Median: 240.0, Mode: 204\n",
      "Range: 438, Variance: 2661.787109375, Standard Deviation: 51.59251020618206\n",
      "\n",
      "Statistics for trestbps:\n",
      "Mean: 131.61170731707318, Median: 130.0, Mode: 120\n",
      "Range: 106, Variance: 306.835409679878, Standard Deviation: 17.516718005376408\n",
      "\n",
      "After Binning (chol):\n",
      "Statistics for chol:\n",
      "Mean: 246.0, Median: 276.4061895551257, Mode: 276.4061895551257\n",
      "Range: 359.1991701244813, Variance: 1992.448015590442, Standard Deviation: 44.636845941334634\n",
      "\n",
      "After Regression (trestbps):\n",
      "Statistics for trestbps:\n",
      "Mean: 131.61170731707318, Median: 131.40491906597907, Mode: 120.60533396201558\n",
      "Range: 32.82357606343098, Variance: 44.10907254282059, Standard Deviation: 6.641466144069439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_statistics(df, attribute):\n",
    "    \"\"\"Calculate and display central tendency and dispersion statistics for a given attribute.\"\"\"\n",
    "    mean = df[attribute].mean()\n",
    "    median = df[attribute].median()\n",
    "    mode = df[attribute].mode()[0]\n",
    "    range_val = df[attribute].max() - df[attribute].min()\n",
    "    variance = df[attribute].var()\n",
    "    std_dev = df[attribute].std()\n",
    "    \n",
    "    print(f\"Statistics for {attribute}:\")\n",
    "    print(f\"Mean: {mean}, Median: {median}, Mode: {mode}\")\n",
    "    print(f\"Range: {range_val}, Variance: {variance}, Standard Deviation: {std_dev}\\n\")\n",
    "\n",
    "# Analyze the 'chol' and 'trestbps' attributes across different techniques\n",
    "print(\"After Ignoring Tuples:\")\n",
    "analyze_statistics(heart_df_ignored, 'chol')\n",
    "analyze_statistics(heart_df_ignored, 'trestbps')\n",
    "\n",
    "print(\"After Filling with Global Constant:\")\n",
    "analyze_statistics(heart_df_global_constant, 'chol')\n",
    "analyze_statistics(heart_df_global_constant, 'trestbps')\n",
    "\n",
    "print(\"After Filling with Mean:\")\n",
    "analyze_statistics(heart_df_mean, 'chol')\n",
    "analyze_statistics(heart_df_mean, 'trestbps')\n",
    "\n",
    "print(\"After Binning (chol):\")\n",
    "analyze_statistics(heart_df_binned, 'chol')\n",
    "\n",
    "print(\"After Regression (trestbps):\")\n",
    "analyze_statistics(heart_df_regression, 'trestbps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation and Conclusion\n",
    "Based on the results, we can draw conclusions about how different missing value handling and noise reduction techniques affect the dataset in terms of central tendency (mean, median, mode) and dispersion (range, variance, standard deviation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
