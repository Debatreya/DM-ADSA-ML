{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining LAB : Experiment 6\n",
    "\n",
    "##  Submitted By:\n",
    "```\n",
    "Name: Debatreya Das\n",
    "Roll No. 12212070\n",
    "CS A4\n",
    "Data Mining LAB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "`Objective`: To compute maximal frequent itemset.\n",
    "\n",
    "Compute candidate 3-itemsets from frequent 2-itemsets using join C3 = L2 x L2. \n",
    "(Hanâ€™s book example)\n",
    "\n",
    "Generalize the algorithm for generating candidate Ci+1 itemsets from frequent Li itemsets Ci+1 = Li x Li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Candidate 3-itemsets (C3) from Frequent 2-itemsets (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Function to generate candidate 3-itemsets from frequent 2-itemsets\n",
    "def generate_candidate_3_itemsets(L2):\n",
    "    C3 = set()  # Store candidates in a set to avoid duplicates\n",
    "    \n",
    "    # Join step: combine two frequent 2-itemsets to form a candidate 3-itemset\n",
    "    for itemset1 in L2:\n",
    "        for itemset2 in L2:\n",
    "            # Join if first two items match (i.e., {a, b} U {a, c} -> {a, b, c})\n",
    "            if len(itemset1.intersection(itemset2)) == 1:\n",
    "                candidate = itemset1.union(itemset2)\n",
    "                if len(candidate) == 3:\n",
    "                    C3.add(frozenset(candidate))  # Frozenset to make itemsets hashable\n",
    "    \n",
    "    return C3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalizing for ð¶ð‘–+1 from ð¿ð‘–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_itemsets(Li, k):\n",
    "    Ci_plus_1 = set()\n",
    "    \n",
    "    # Join step: combine k-itemsets that differ by only one item\n",
    "    for itemset1 in Li:\n",
    "        for itemset2 in Li:\n",
    "            # Join if the first (k-1) items are the same\n",
    "            if len(itemset1.intersection(itemset2)) == k-1:\n",
    "                candidate = itemset1.union(itemset2)\n",
    "                if len(candidate) == k + 1:\n",
    "                    Ci_plus_1.add(frozenset(candidate))\n",
    "    \n",
    "    return Ci_plus_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "`Objective`: To develop prune operation using apriory property.\n",
    "\n",
    "Prune unnecessary 3-itemsets from the set of generated 3-itemsets C3 to make C3 to \n",
    "set of frequent 3-itemsets L3. (Han book example)\n",
    "\n",
    "Generalize the algorithm for pruning unnecessary i-itemsets from the set of \n",
    "generated i-itemsets Ci to make Ci to set of frequent i-itemsets Li.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Itemset Prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_3_itemsets(C3, L2):\n",
    "    pruned_C3 = set()\n",
    "    \n",
    "    # For each candidate 3-itemset\n",
    "    for candidate in C3:\n",
    "        valid = True\n",
    "        # Generate all 2-itemset subsets (since we're pruning 3-itemsets)\n",
    "        for subset in combinations(candidate, 2):\n",
    "            # If any 2-itemset subset is not in L2, prune the candidate\n",
    "            if frozenset(subset) not in L2:\n",
    "                valid = False\n",
    "                break\n",
    "        # If all 2-itemset subsets are frequent, keep the 3-itemset\n",
    "        if valid:\n",
    "            pruned_C3.add(candidate)\n",
    "    \n",
    "    return pruned_C3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prunning infrequent itemset for Ci+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_candidates(Ci_plus_1, Li):\n",
    "    pruned_Ci_plus_1 = set()\n",
    "    \n",
    "    for candidate in Ci_plus_1:\n",
    "        # Generate all k-sized subsets of the candidate\n",
    "        valid = True\n",
    "        for subset in combinations(candidate, len(candidate)-1):\n",
    "            if frozenset(subset) not in Li:\n",
    "                valid = False\n",
    "                break\n",
    "        if valid:\n",
    "            pruned_Ci_plus_1.add(candidate)\n",
    "    \n",
    "    return pruned_Ci_plus_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C\n",
    "\n",
    "Write Apriori algorithm using the above join and prune procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent 1-itemsets: {frozenset({3}), frozenset({2}), frozenset({1}), frozenset({4})}\n",
      "Frequent 2-itemsets: {frozenset({3, 4}), frozenset({1, 4}), frozenset({2, 3}), frozenset({1, 2}), frozenset({2, 4}), frozenset({1, 3})}\n",
      "Frequent 3-itemsets: {frozenset({1, 2, 3}), frozenset({2, 3, 4}), frozenset({1, 3, 4}), frozenset({1, 2, 4})}\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "# Helper function to generate all candidate itemsets from a dataset\n",
    "def get_itemsets_from_transactions(transactions, k):\n",
    "    itemsets = set()\n",
    "    for transaction in transactions:\n",
    "        for itemset in combinations(transaction, k):\n",
    "            itemsets.add(frozenset(itemset))\n",
    "    return itemsets\n",
    "\n",
    "# Helper function to calculate support of itemsets\n",
    "def calculate_support(transactions, candidates):\n",
    "    support_count = {itemset: 0 for itemset in candidates}\n",
    "    for transaction in transactions:\n",
    "        for candidate in candidates:\n",
    "            if candidate.issubset(transaction):\n",
    "                support_count[candidate] += 1\n",
    "    return support_count\n",
    "\n",
    "# Apriori algorithm\n",
    "def apriori(transactions, min_support):\n",
    "    # Step 1: Generate frequent 1-itemsets (L1)\n",
    "    single_items = chain.from_iterable(transactions)\n",
    "    item_count = {}\n",
    "    for item in single_items:\n",
    "        item_count[frozenset([item])] = item_count.get(frozenset([item]), 0) + 1\n",
    "    \n",
    "    # Filter 1-itemsets by min support\n",
    "    L1 = {itemset for itemset, count in item_count.items() if count >= min_support}\n",
    "    frequent_itemsets = {1: L1}\n",
    "    \n",
    "    k = 2\n",
    "    Li = L1\n",
    "    while Li:\n",
    "        # Step 2: Generate candidates Ci+1 from frequent Li itemsets\n",
    "        candidates = generate_candidate_itemsets(Li, k-1)\n",
    "        \n",
    "        # Step 3: Calculate support for candidates\n",
    "        support_count = calculate_support(transactions, candidates)\n",
    "        \n",
    "        # Step 4: Prune candidates whose support is less than min_support\n",
    "        Li = {itemset for itemset, count in support_count.items() if count >= min_support}\n",
    "        \n",
    "        if Li:\n",
    "            frequent_itemsets[k] = Li\n",
    "        k += 1\n",
    "    \n",
    "    return frequent_itemsets\n",
    "\n",
    "# Example transactions (dataset)\n",
    "transactions = [\n",
    "    {1, 2, 3},\n",
    "    {1, 2, 4},\n",
    "    {2, 3, 4},\n",
    "    {1, 3, 4},\n",
    "    {1, 2, 3, 4}\n",
    "]\n",
    "\n",
    "# Minimum support threshold\n",
    "min_support = 2\n",
    "\n",
    "# Run the Apriori algorithm\n",
    "frequent_itemsets = apriori(transactions, min_support)\n",
    "\n",
    "# Output the result\n",
    "for k, itemsets in frequent_itemsets.items():\n",
    "    print(f\"Frequent {k}-itemsets: {itemsets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2 Itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 = [frozenset([1, 2]), frozenset([1, 3]), frozenset([2, 3]), frozenset([2, 4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate candidate 3-itemsets (C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate 3-itemsets: {frozenset({1, 2, 3}), frozenset({2, 3, 4}), frozenset({1, 2, 4})}\n"
     ]
    }
   ],
   "source": [
    "C3 = generate_candidate_3_itemsets(L2)\n",
    "print(\"Candidate 3-itemsets:\", C3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Generalized candidate generation for k+1 from k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized candidate 3-itemsets: {frozenset({1, 2, 3}), frozenset({2, 3, 4}), frozenset({1, 2, 4})}\n"
     ]
    }
   ],
   "source": [
    "L3 = generate_candidate_itemsets(L2, 2)\n",
    "print(\"Generalized candidate 3-itemsets:\", L3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Itemset Prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned 3-itemsets: {frozenset({1, 2, 3})}\n"
     ]
    }
   ],
   "source": [
    "pruned_C3 = prune_3_itemsets(C3, L2)\n",
    "print(\"Pruned 3-itemsets:\", pruned_C3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalized Pruning the candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned 3-itemsets: {frozenset({1, 2, 3})}\n"
     ]
    }
   ],
   "source": [
    "pruned_L3 = prune_candidates(L3, L2)\n",
    "print(\"Pruned 3-itemsets:\", pruned_L3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
